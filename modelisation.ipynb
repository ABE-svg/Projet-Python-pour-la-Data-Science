{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de téléchargement des données sur les accidents corporels\n",
    "def telecharge(url_data,filename, path):\n",
    "    # Vérifie si le dossier 'data' existe, sinon le crée\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    #télécharge les données avec l'url\n",
    "    response = requests.get(url_data)\n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(path, filename)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Fichier {filename} téléchargé avec succès:{file_path}\")\n",
    "    else:\n",
    "        print(f\"Echec de téléchargement pour {filename}. Statut: {response.status_code}\")\n",
    "\n",
    "# API pour accéder à l'url de téléchargement\n",
    "url_root=\"https://www.data.gouv.fr/api/1/datasets/53698f4ca3a729239d2036df/resources/\"\n",
    "urls={\n",
    "    \"usagers-2023.csv\":\"68848e2a-28dd-4efc-9d5f-d512f7dbe66f\",\n",
    "    \"vehicules-2023.csv\":\"146a42f5-19f0-4b3e-a887-5cd8fbef057b\",\n",
    "    \"lieux-2023.csv\":\"8bef19bf-a5e4-46b3-b5f9-a145da4686bc\",\n",
    "    \"caract-2023.csv\":\"104dbb32-704f-4e99-a71e-43563cb604f2\"\n",
    "}\n",
    "path='/home/onyxia/Projet-Python-pour-la-Data-Science/data'\n",
    "\n",
    "for filename, resource_id in urls.items():\n",
    "    url=url_root+resource_id\n",
    "    response1=requests.get(url)\n",
    "    if response1.status_code==200:\n",
    "        data=response1.json()\n",
    "        url_data=data['url']\n",
    "    else:\n",
    "        print(\"downloading failed\")\n",
    "    telecharge(url_data,filename,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base des usagers \n",
    "df_usagers = pd.read_csv(r\"/home/onyxia/Projet-Python-pour-la-Data-Science/data/usagers-2023.csv\", sep = ';')\n",
    "df_usagers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base des véhicules \n",
    "df_vehicules = pd.read_csv(r\"/home/onyxia/Projet-Python-pour-la-Data-Science/data/vehicules-2023.csv\", sep = ';')\n",
    "df_vehicules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base des lieux \n",
    "df_lieux = pd.read_csv(r\"/home/onyxia/Projet-Python-pour-la-Data-Science/data/lieux-2023.csv\", sep = ';')\n",
    "df_lieux.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caract = pd.read_csv(r\"/home/onyxia/Projet-Python-pour-la-Data-Science/data/caract-2023.csv\", sep = ';')\n",
    "df_caract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_usagers.merge(df_vehicules, on=[\"Num_Acc\",\"id_vehicule\",\"num_veh\"], how=\"inner\") \n",
    "df_merge = df_merge.merge(df_lieux, on=\"Num_Acc\", how=\"inner\")\n",
    "df_merge = df_merge.merge(df_caract, on=\"Num_Acc\", how=\"inner\")\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages nécéssaire\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de l'âge des piétons\n",
    "df_merge[\"Age\"] = 2023-df_merge[\"an_nais\"]\n",
    "# Distribution de l'âge\n",
    "df_merge[\"Age\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supression des variables d'identification\n",
    "var=[\"Num_Acc\",\"jour\",\"an\",\"com\",\"adr\",\"lat\",\"long\",\"voie\",\"v1\",\"v2\",\"id_vehicule\",\"num_veh\",\"id_usager\",\"an_nais\", \"dep\"]\n",
    "Num_acc=df_merge[\"Num_Acc\"]\n",
    "df_merge.drop(var, axis=1,inplace=True)\n",
    "\n",
    "# pourcentage des valeurs manquantes par variables \n",
    "df_merge.isna().sum()[df_merge.isna().sum()!=0]/len(df_merge)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.drop([\"occutc\",\"lartpc\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation des valeurs manquantes de l'âge\n",
    "sns.boxplot(data=df_merge, x=df_merge['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge[\"Age\"]=df_merge[\"Age\"].fillna(df_merge[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recodage des variables trajet et actp de la base usager\n",
    "df_merge[\"trajet\"]=df_merge[\"trajet\"].replace(0, value=-1)\n",
    "df_merge[\"actp\"]=df_merge[\"actp\"].replace(0, value=-1)\n",
    "\n",
    "# variables de type object de la base\n",
    "df_merge.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion des variables de type object en variables numériques\n",
    "def replace_pr(val):\n",
    "    if len(val.split())==1:\n",
    "        val=val\n",
    "    else:\n",
    "        if len(val.split())>1:\n",
    "            val=val.split()[1]\n",
    "        else:\n",
    "            val=\"-1\"\n",
    "    return val\n",
    "df_merge[\"pr\"]=df_merge[\"pr\"].apply(func=replace_pr)\n",
    "df_merge[\"pr\"]=df_merge[\"pr\"].astype(float)\n",
    "df_merge[\"pr1\"]=df_merge[\"pr1\"].apply(func=replace_pr)\n",
    "df_merge[\"pr1\"]=df_merge[\"pr1\"].astype(float)\n",
    "def rep_virgule(val):\n",
    "    val=val.replace(\",\",\".\")\n",
    "    return val\n",
    "df_merge[\"larrout\"]=df_merge[\"larrout\"].apply(rep_virgule)\n",
    "df_merge[\"larrout\"]=df_merge[\"larrout\"].astype(float)\n",
    "def heure(val):\n",
    "    val=val.split(\":\")[0]\n",
    "    return val\n",
    "df_merge[\"hrmn\"]=df_merge[\"hrmn\"].apply(func=heure)\n",
    "df_merge[\"hrmn\"]=df_merge[\"hrmn\"].astype(float)\n",
    "\n",
    "df_merge[\"nbv\"]=df_merge[\"nbv\"].str.strip()\n",
    "df_merge[\"nbv\"]=df_merge[\"nbv\"].replace(\"#VALEURMULTI\",\"-1\")\n",
    "df_merge[\"nbv\"]=df_merge[\"nbv\"].astype(float)\n",
    "\n",
    "df_merge[\"actp\"]=df_merge[\"actp\"].replace([\"A\",\"B\"],[\"10\",\"11\"])\n",
    "df_merge[\"actp\"]=df_merge[\"actp\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des colonnes qui ont plus de 20% de valeurs non renseignés\n",
    "diction=[]\n",
    "for column in df_merge.columns:\n",
    "    if ((len(df_merge[df_merge[column]==-1][column])/df_merge.shape[0]*100)>=20) == True:\n",
    "        diction.append(column)\n",
    "        \n",
    "df_merge=df_merge.drop(diction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace toute les valeurs non renseignées des variables restantes par le mode\n",
    "diction2=[]\n",
    "for column in df_merge.columns:\n",
    "    if len(df_merge[df_merge[column]==-1][column])/df_merge.shape[0]!=0:\n",
    "        diction2.append(column)\n",
    "\n",
    "for col in diction2:\n",
    "    mode=df_merge[col].value_counts().idxmax()\n",
    "    df_merge[col]=df_merge[col].replace(-1,mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On caractérise chaque accident par le niveau de gravité le plus haut\n",
    "df_merge[\"Num_Acc\"]=Num_acc\n",
    "import numpy as np\n",
    "id_acc=df_merge[\"Num_Acc\"].unique()\n",
    "index_true=[]\n",
    "for i in id_acc:\n",
    "    df_id=df_merge[df_merge[\"Num_Acc\"]==i]\n",
    "    n_grav=np.max(df_id[\"grav\"])\n",
    "    index=df_merge[(df_merge[\"Num_Acc\"]==i) & (df_merge[\"grav\"]==n_grav)].index[0]\n",
    "    #if len(index)!=0:\n",
    "    #df_merge.drop(index=index, inplace=True)\n",
    "    index_true.append(index)\n",
    "        \n",
    "df_merge.drop([\"Num_Acc\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Niveau de gravité de l'accident présente dans la nouvelle base\n",
    "df_merge=df_merge.loc[index_true]\n",
    "df_merge[\"grav\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les accidents enregistrés, aucun n'a laisser toutes les personnes impliquées indemnes.\n",
    "\n",
    "On recode la variable \"gravité\" par: \n",
    "- 2: niveau de gravité **grave** (2)\n",
    "- 3: niveau de gravité **moyen** (1)\n",
    "- 4: niveau de gravité **faible** (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recodage de la gravité de l'accident\n",
    "df_merge[\"grav\"]=df_merge[\"grav\"].replace([3,4], value=[1,0])\n",
    "# distribution de la gravité\n",
    "df_merge[\"grav\"].value_counts()/df_merge.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrélation entre les variables\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df_merge.corr(),annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on retire les variables qui ont une forte corrélation avec d'autres\n",
    "df_merge=df_merge.drop([\"place\",\"agg\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en utilisant une regression lasso\n",
    "numeric_var=[\"Age\",'hrmn','vma']\n",
    "lasso_x=df_merge.drop([\"grav\"],axis=1)\n",
    "categorical_var=lasso_x.drop(numeric_var, axis=1).columns\n",
    "lasso_y=df_merge[\"grav\"]\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"scale\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"one-hot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "base=categorical_pipeline.fit_transform(lasso_x.drop(columns=numeric_var,axis=1))\n",
    "base_cont=numeric_pipeline.fit_transform(lasso_x[numeric_var])\n",
    "data=pd.DataFrame(data=base, columns=categorical_pipeline.get_feature_names_out())\n",
    "data[numeric_var]=base_cont\n",
    "\n",
    "my_alphas = np.array([0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.25, 0.5, 0.8, 1.0])\n",
    "\n",
    "lcv = LassoCV(alphas=my_alphas, fit_intercept=False, random_state=0, cv=5).fit(\n",
    "    data, lasso_y\n",
    ")\n",
    "print(\"alpha optimal :\", lcv.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du lasso\n",
    "model = Lasso(fit_intercept=False, alpha=lcv.alpha_)\n",
    "lasso_optimal=model.fit(data, lasso_y)\n",
    "data.columns[np.abs(lasso_optimal.coef_)>0] # variables sélectionner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model=data[data.columns[np.abs(lasso_optimal.coef_)>0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implémentation de la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_model,lasso_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'penalty':[\"l2\",None], 'solver':[\"newton-cg\"]}\n",
    "cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid= GridSearchCV(LogisticRegression(multi_class=\"multinomial\",class_weight=\"balanced\"), params, cv=cv)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"best params:\",grid.best_params_)\n",
    "print(\"best score:\",grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=grid.best_estimator_\n",
    "acc_train = accuracy_score(y_train, model.predict(x_train))\n",
    "acc_test = accuracy_score(y_test, model.predict(x_test))\n",
    "print(\"Training Accuracy:\", round(acc_train, 2))\n",
    "print(\"Test Accuracy:\", round(acc_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "importances1 = model.coef_[0]\n",
    "odds_ratios1 = pd.Series(np.exp(importances1), index=data_model.columns).sort_values() #coefficient des variables dans le modèle\n",
    "plt.subplot(1,2,1)\n",
    "odds_ratios1.tail(15).plot(kind=\"barh\")\n",
    "plt.ylabel(\"Odds Ratio\")\n",
    "\n",
    "importances2 = model.coef_[1]\n",
    "odds_ratios2 = pd.Series(np.exp(importances2), index=data_model.columns).sort_values() #coefficient des variables dans le modèle\n",
    "plt.subplot(1,2,2)\n",
    "odds_ratios2.tail(15).plot(kind=\"barh\")\n",
    "plt.ylabel(\"Odds Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'utilisation de la ceinture de sécurité seule augmente la chance que la ravité de l'accident soit moyenne de 82%.\n",
    "- Lorsque la voiture se trouve entre deux files avant l'accident, la gravité de l'accident à 54% d'être moyenne que d'être faible\n",
    "- un véhicule scooter<50cm3, l'autoroute, heurté une glissière en béton augmentent la chance d'avoir un accident de gravité moyenne de 54%,51%,47% respectivement.\n",
    "- une collision de trois véhicules et plus-en chaine augmentent la chance d'avoir un accident de gravité moyenne de 45%.\n",
    " - les caractéristiques suivantes: une manoeuvre d'évitement, un accident sur piste cyclable, heurté un véhicule en stationnement, avec un scooter > 50cm3 et <=125cm3, avoir un accident sur la chaussée, ou avec un véhicule léger, ou encore sous une pluie légère,  augmentent la chance d'avoir un accident de gravité moyenne entre 15% et 30%. \n",
    "\n",
    " - Avoir un accident sur un cyclomoteur<50cm3 ou sur une motocyclette augmente la probabilité que l'accident soit grave de plus de 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "odds_ratios1.head(10).plot(kind=\"barh\")\n",
    "plt.ylabel(\"Odds Ratio\")\n",
    "plt.subplot(1,2,2)\n",
    "odds_ratios2.head(10).plot(kind=\"barh\")\n",
    "plt.ylabel(\"Odds Ratio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
